@misc{hueholt_assessing_2022,
	title = {Assessing {Outcomes} in {Stratospheric} {Aerosol} {Injection} {Scenarios} {Shortly} {After} {Deployment}},
	abstract = {Current global actions to reduce greenhouse gas emissions are very likely to be insufficient to meet climate targets outlined under the Paris Agreement. This motivates performing research on possible methods for intervening in the Earth system to minimize climate risk while decarbonization efforts continue. One such hypothetical climate intervention is stratospheric aerosol injection (SAI), where reflective particles would be released into the stratosphere to cool the planet by reducing solar insolation. The climate response to SAI is not well understood, particularly on short-term time horizons frequently used by decision makers and planning practitioners to assess climate information. This knowledge gap limits informed discussion of SAI outside the scientific community. We demonstrate two framings to explore the climate response in the decade after SAI deployment in modeling experiments with parallel SAI and no-SAI simulations. The first framing, which we call a snapshot around deployment, displays change over time within the SAI scenarios and applies to the question “What happens before and after SAI is deployed in the model?” The second framing, the intervention impact, displays the difference between the SAI and no-SAI simulations, corresponding to the question “What is the impact of a given intervention relative to climate change with no intervention?” We apply these framings to annual mean 2-meter temperature, precipitation, and a precipitation extreme in the first two experiments to use ensembles of Earth system models that comprehensively represent both the SAI injection process and climate response, and connect these results to implications for other climate variables. The parallel SAI and no-SAI simulations in these experiments allow us to explore the climate response in the context of the response to SAI, the underlying greenhouse gas forcing scenario, and the noise from internal climate variability.},
	publisher = {In prep},
	author = {Hueholt, Daniel M. and Barnes, Elizabeth A. and Hurrell, James W. and Richter, Jadwiga H. and Sun, Lantao},
	year = {2022},
}

@article{gebru_datasheets_2020,
	title = {Datasheets for {Datasets}},
	url = {http://arxiv.org/abs/1803.09010},
	abstract = {The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.},
	urldate = {2021-09-14},
	journal = {arXiv:1803.09010 [cs]},
	author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daumé III, Hal and Crawford, Kate},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.09010},
}
